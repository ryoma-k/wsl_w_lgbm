{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 教師あり二値分類（クラス9のみ正）のノートブック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "N_COMPONENTS = 50\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = load_mnist_pca_train_test_val(\n",
    "    n_components=N_COMPONENTS, test_size=TEST_SIZE, val_size=VAL_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルの変更（クラス9のみ正）\n",
    "y_train = (y_train == 9).astype(int)\n",
    "y_val = (y_val == 9).astype(int)\n",
    "y_test = (y_test == 9).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_with_custom_loss(X_train, X_valid, y_train, y_valid):\n",
    "\n",
    "    \"\"\"Train LightGBM with custom loss function.\"\"\"\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, free_raw_data=False)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"verbose\": -1,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"num_boost_round\": 200,\n",
    "    }\n",
    "    valid_accuracies = []\n",
    "\n",
    "    def record_accuracies(p: lgb.Booster, train_data: lgb.Dataset, valid_data: lgb.Dataset):\n",
    "        valid_pred = (p.predict(valid_data.data) > 0.5).astype(int)\n",
    "        valid_acc = accuracy_score(valid_data.label, valid_pred)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        print(valid_acc)\n",
    "    \n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lambda p: record_accuracies(p.model, train_data, valid_data)]\n",
    "    )\n",
    "    return gbm, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryoma.kobayashi/gits/techblog_git/wsl_w_lgbm/.venv/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9043333333333333\n",
      "0.9043333333333333\n",
      "0.9043333333333333\n",
      "0.9043333333333333\n",
      "0.9055\n",
      "0.92975\n",
      "0.93825\n",
      "0.9440833333333334\n",
      "0.94925\n",
      "0.9528333333333333\n",
      "0.95525\n",
      "0.9581666666666667\n",
      "0.9595833333333333\n",
      "0.9604166666666667\n",
      "0.9615\n",
      "0.9638333333333333\n",
      "0.9648333333333333\n",
      "0.96575\n",
      "0.9669166666666666\n",
      "0.9674166666666667\n",
      "0.9681666666666666\n",
      "0.9694166666666667\n",
      "0.9698333333333333\n",
      "0.9705\n",
      "0.9713333333333334\n",
      "0.97125\n",
      "0.9723333333333334\n",
      "0.97275\n",
      "0.973\n",
      "0.9735\n",
      "0.974\n",
      "0.9740833333333333\n",
      "0.9746666666666667\n",
      "0.9746666666666667\n",
      "0.97525\n",
      "0.976\n",
      "0.9764166666666667\n",
      "0.97675\n",
      "0.9766666666666667\n",
      "0.97725\n",
      "0.97725\n",
      "0.9770833333333333\n",
      "0.9776666666666667\n",
      "0.97825\n",
      "0.9783333333333334\n",
      "0.9781666666666666\n",
      "0.9780833333333333\n",
      "0.9785\n",
      "0.979\n",
      "0.9790833333333333\n",
      "0.979\n",
      "0.9795833333333334\n",
      "0.9799166666666667\n",
      "0.9800833333333333\n",
      "0.9805833333333334\n",
      "0.9805833333333334\n",
      "0.9805\n",
      "0.98075\n",
      "0.9811666666666666\n",
      "0.9808333333333333\n",
      "0.9810833333333333\n",
      "0.9810833333333333\n",
      "0.9815\n",
      "0.9814166666666667\n",
      "0.9818333333333333\n",
      "0.98175\n",
      "0.9819166666666667\n",
      "0.98175\n",
      "0.98175\n",
      "0.9819166666666667\n",
      "0.9821666666666666\n",
      "0.9824166666666667\n",
      "0.9824166666666667\n",
      "0.98275\n",
      "0.9829166666666667\n",
      "0.9828333333333333\n",
      "0.98275\n",
      "0.9833333333333333\n",
      "0.9833333333333333\n",
      "0.9835\n",
      "0.9835\n",
      "0.9836666666666667\n",
      "0.98375\n",
      "0.9834166666666667\n",
      "0.9835833333333334\n",
      "0.9839166666666667\n",
      "0.984\n",
      "0.9841666666666666\n",
      "0.9844166666666667\n",
      "0.9843333333333333\n",
      "0.9840833333333333\n",
      "0.98425\n",
      "0.9844166666666667\n",
      "0.9845833333333334\n",
      "0.9846666666666667\n",
      "0.9849166666666667\n",
      "0.985\n",
      "0.9850833333333333\n",
      "0.9849166666666667\n",
      "0.985\n",
      "0.9850833333333333\n",
      "0.9850833333333333\n",
      "0.985\n",
      "0.9850833333333333\n",
      "0.98525\n",
      "0.9851666666666666\n",
      "0.9853333333333333\n",
      "0.9851666666666666\n",
      "0.9853333333333333\n",
      "0.9856666666666667\n",
      "0.9856666666666667\n",
      "0.98575\n",
      "0.9856666666666667\n",
      "0.9856666666666667\n",
      "0.9856666666666667\n",
      "0.9858333333333333\n",
      "0.9858333333333333\n",
      "0.9858333333333333\n",
      "0.9859166666666667\n",
      "0.9860833333333333\n",
      "0.9858333333333333\n",
      "0.986\n",
      "0.9861666666666666\n",
      "0.9863333333333333\n",
      "0.98625\n",
      "0.9863333333333333\n",
      "0.9863333333333333\n",
      "0.9863333333333333\n",
      "0.98625\n",
      "0.9863333333333333\n",
      "0.9865\n",
      "0.9865\n",
      "0.9866666666666667\n",
      "0.9866666666666667\n",
      "0.9868333333333333\n",
      "0.987\n",
      "0.987\n",
      "0.98675\n",
      "0.9869166666666667\n",
      "0.987\n",
      "0.9870833333333333\n",
      "0.9870833333333333\n",
      "0.9871666666666666\n",
      "0.9870833333333333\n",
      "0.98725\n",
      "0.9873333333333333\n",
      "0.9873333333333333\n",
      "0.9875\n",
      "0.9873333333333333\n",
      "0.9873333333333333\n",
      "0.9870833333333333\n",
      "0.98725\n",
      "0.9873333333333333\n",
      "0.9875\n",
      "0.9875\n",
      "0.9875\n",
      "0.9875\n",
      "0.9875\n",
      "0.9875\n",
      "0.9874166666666667\n",
      "0.9874166666666667\n",
      "0.9874166666666667\n",
      "0.9875833333333334\n",
      "0.98775\n",
      "0.98775\n",
      "0.9876666666666667\n",
      "0.9876666666666667\n",
      "0.9876666666666667\n",
      "0.9876666666666667\n",
      "0.98775\n",
      "0.98775\n",
      "0.98775\n",
      "0.9878333333333333\n",
      "0.98775\n",
      "0.9875833333333334\n",
      "0.98775\n",
      "0.9876666666666667\n",
      "0.9876666666666667\n",
      "0.9875833333333334\n",
      "0.98775\n",
      "0.98775\n",
      "0.9879166666666667\n",
      "0.98775\n",
      "0.98775\n",
      "0.9876666666666667\n",
      "0.9876666666666667\n",
      "0.98775\n",
      "0.98775\n",
      "0.9878333333333333\n",
      "0.9878333333333333\n",
      "0.9879166666666667\n",
      "0.9879166666666667\n",
      "0.9879166666666667\n",
      "0.9879166666666667\n",
      "0.9878333333333333\n",
      "0.9876666666666667\n",
      "0.9879166666666667\n",
      "0.9879166666666667\n",
      "0.988\n",
      "0.9880833333333333\n",
      "Accuracy: 0.9880833333333333\n"
     ]
    }
   ],
   "source": [
    "gbm, valid_accuracies =train_lgbm_with_custom_loss(X_train, X_val, y_train, y_val)\n",
    "y_pred = gbm.predict(X_val)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_val, (y_pred > 0.5).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"sup_bin9_valid_accuracies.npy\", valid_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
