{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 50\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "BAG_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = load_mnist_pca_train_test_val(\n",
    "    n_components=N_COMPONENTS, test_size=TEST_SIZE, val_size=VAL_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = rewrite_label_with_binary_setting(X_train, y_train)\n",
    "X_val, y_val = rewrite_label_with_binary_setting(X_val, y_val)\n",
    "X_test, y_test = rewrite_label_with_binary_setting(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000個の正例を持つデータセットを作成する\n",
    "X_train, y_train = rewrite_label_with_pu_setting(X_train, y_train, positive_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_with_custom_loss(X_train, X_valid, y_train, y_valid):\n",
    "\n",
    "    \"\"\"Train LightGBM with custom loss function.\"\"\"\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, init_score=np.full_like(y_train, np.log(1.), dtype=float), free_raw_data=False)\n",
    "    train_data._pu_label = y_train\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, free_raw_data=False)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"custom\",\n",
    "        \"metric\": \"custom\",\n",
    "        \"verbose\": -1,\n",
    "        # 学習が不安定なので、小さめの値を設定します\n",
    "        # 今回は単純な検証目的なので、ご容赦ください\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"num_boost_round\": 200,\n",
    "    }\n",
    "    valid_accuracies = []\n",
    "\n",
    "    def record_accuracies(p: lgb.Booster, train_data: lgb.Dataset, valid_data: lgb.Dataset):\n",
    "        valid_pred = (p.predict(valid_data.data) > 0.).astype(int)\n",
    "        valid_acc = accuracy_score(valid_data.label, valid_pred)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        print(valid_acc)\n",
    "    \n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],\n",
    "        fobj=pu_loss_objective,\n",
    "        feval=binary_metric,\n",
    "        callbacks=[lambda p: record_accuracies(p.model, train_data, valid_data)]\n",
    "    )\n",
    "    return gbm, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryoma.kobayashi/gits/techblog_git/wsl_w_lgbm/.venv/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80375\n",
      "0.8129166666666666\n",
      "0.796\n",
      "0.7951666666666667\n",
      "0.813\n",
      "0.8140833333333334\n",
      "0.8193333333333334\n",
      "0.8191666666666667\n",
      "0.82025\n",
      "0.8205\n",
      "0.8219166666666666\n",
      "0.8223333333333334\n",
      "0.8226666666666667\n",
      "0.8204166666666667\n",
      "0.823\n",
      "0.82325\n",
      "0.8235\n",
      "0.82425\n",
      "0.826\n",
      "0.8248333333333333\n",
      "0.82525\n",
      "0.8229166666666666\n",
      "0.822\n",
      "0.8239166666666666\n",
      "0.8253333333333334\n",
      "0.8269166666666666\n",
      "0.8274166666666667\n",
      "0.8285\n",
      "0.8291666666666667\n",
      "0.8279166666666666\n",
      "0.8289166666666666\n",
      "0.8294166666666667\n",
      "0.8291666666666667\n",
      "0.8294166666666667\n",
      "0.82925\n",
      "0.8294166666666667\n",
      "0.8300833333333333\n",
      "0.8298333333333333\n",
      "0.8288333333333333\n",
      "0.8288333333333333\n",
      "0.8288333333333333\n",
      "0.8280833333333333\n",
      "0.8286666666666667\n",
      "0.8300833333333333\n",
      "0.8310833333333333\n",
      "0.82925\n",
      "0.83075\n",
      "0.83175\n",
      "0.8335\n",
      "0.8335833333333333\n",
      "0.834\n",
      "0.83475\n",
      "0.8361666666666666\n",
      "0.8371666666666666\n",
      "0.8394166666666667\n",
      "0.8395\n",
      "0.8411666666666666\n",
      "0.84\n",
      "0.84025\n",
      "0.8406666666666667\n",
      "0.84175\n",
      "0.8413333333333334\n",
      "0.84275\n",
      "0.84475\n",
      "0.84525\n",
      "0.8459166666666667\n",
      "0.8455\n",
      "0.8466666666666667\n",
      "0.8470833333333333\n",
      "0.84775\n",
      "0.84775\n",
      "0.8479166666666667\n",
      "0.8488333333333333\n",
      "0.8494166666666667\n",
      "0.8484166666666667\n",
      "0.8476666666666667\n",
      "0.8485833333333334\n",
      "0.849\n",
      "0.849\n",
      "0.8496666666666667\n",
      "0.8500833333333333\n",
      "0.8504166666666667\n",
      "0.8515833333333334\n",
      "0.8520833333333333\n",
      "0.8519166666666667\n",
      "0.8531666666666666\n",
      "0.854\n",
      "0.8551666666666666\n",
      "0.8555\n",
      "0.8559166666666667\n",
      "0.8578333333333333\n",
      "0.8579166666666667\n",
      "0.8575\n",
      "0.8580833333333333\n",
      "0.8586666666666667\n",
      "0.8586666666666667\n",
      "0.8595\n",
      "0.8600833333333333\n",
      "0.8608333333333333\n",
      "0.86075\n",
      "0.8609166666666667\n",
      "0.8605\n",
      "0.8610833333333333\n",
      "0.8608333333333333\n",
      "0.86075\n",
      "0.8611666666666666\n",
      "0.8608333333333333\n",
      "0.8604166666666667\n",
      "0.8609166666666667\n",
      "0.8611666666666666\n",
      "0.8615\n",
      "0.8619166666666667\n",
      "0.8620833333333333\n",
      "0.8624166666666667\n",
      "0.8629166666666667\n",
      "0.86275\n",
      "0.8635\n",
      "0.8629166666666667\n",
      "0.86275\n",
      "0.8625\n",
      "0.8620833333333333\n",
      "0.8620833333333333\n",
      "0.8626666666666667\n",
      "0.8635\n",
      "0.8633333333333333\n",
      "0.8635\n",
      "0.8634166666666667\n",
      "0.8639166666666667\n",
      "0.8641666666666666\n",
      "0.8649166666666667\n",
      "0.86525\n",
      "0.8644166666666667\n",
      "0.8643333333333333\n",
      "0.8638333333333333\n",
      "0.8655833333333334\n",
      "0.8650833333333333\n",
      "0.8658333333333333\n",
      "0.86575\n",
      "0.8666666666666667\n",
      "0.86725\n",
      "0.868\n",
      "0.8679166666666667\n",
      "0.8691666666666666\n",
      "0.8700833333333333\n",
      "0.8703333333333333\n",
      "0.8705\n",
      "0.871\n",
      "0.87075\n",
      "0.8720833333333333\n",
      "0.87325\n",
      "0.87325\n",
      "0.8735833333333334\n",
      "0.8741666666666666\n",
      "0.8745\n",
      "0.8758333333333334\n",
      "0.8759166666666667\n",
      "0.8754166666666666\n",
      "0.8754166666666666\n",
      "0.8760833333333333\n",
      "0.8770833333333333\n",
      "0.8771666666666667\n",
      "0.87775\n",
      "0.87775\n",
      "0.8795\n",
      "0.87875\n",
      "0.8793333333333333\n",
      "0.8795833333333334\n",
      "0.8801666666666667\n",
      "0.8805\n",
      "0.8831666666666667\n",
      "0.8835833333333334\n",
      "0.8835833333333334\n",
      "0.884\n",
      "0.8849166666666667\n",
      "0.8861666666666667\n",
      "0.8855\n",
      "0.8854166666666666\n",
      "0.8873333333333333\n",
      "0.8865\n",
      "0.8875833333333333\n",
      "0.88825\n",
      "0.88775\n",
      "0.8869166666666667\n",
      "0.8865\n",
      "0.8875833333333333\n",
      "0.88875\n",
      "0.8883333333333333\n",
      "0.8884166666666666\n",
      "0.88925\n",
      "0.8895\n",
      "0.8900833333333333\n",
      "0.89025\n",
      "0.89025\n",
      "0.891\n",
      "0.8915833333333333\n",
      "0.8898333333333334\n",
      "0.888\n",
      "0.8893333333333333\n",
      "0.8894166666666666\n",
      "0.8895833333333333\n",
      "Accuracy: 0.8895833333333333\n"
     ]
    }
   ],
   "source": [
    "gbm, valid_accuracies =train_lgbm_with_custom_loss(X_train, X_val, y_train, y_val)\n",
    "y_pred = gbm.predict(X_val)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_val, (y_pred > 0.).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pu_valid_accuracies.npy\", valid_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
