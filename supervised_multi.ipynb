{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 教師あり多クラス分類のノートブック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "N_COMPONENTS = 50\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = load_mnist_pca_train_test_val(\n",
    "    n_components=N_COMPONENTS, test_size=TEST_SIZE, val_size=VAL_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMの学習用の関数\n",
    "def train_lgbm_with_custom_loss(X_train, X_valid, y_train, y_valid):\n",
    "\n",
    "    \"\"\"Train LightGBM with custom loss function.\"\"\"\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, free_raw_data=False)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"verbose\": -1,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"num_boost_round\": 200,\n",
    "        \"num_class\": 10,\n",
    "    }\n",
    "    valid_accuracies = []\n",
    "\n",
    "    def record_accuracies(p: lgb.Booster, train_data: lgb.Dataset, valid_data: lgb.Dataset):\n",
    "        valid_pred = p.predict(valid_data.data).argmax(-1)\n",
    "        valid_acc = accuracy_score(valid_data.label, valid_pred)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        print(valid_acc)\n",
    "    \n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lambda p: record_accuracies(p.model, train_data, valid_data)]\n",
    "    )\n",
    "    return gbm, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryoma.kobayashi/gits/techblog_git/wsl_w_lgbm/.venv/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.8221666666666667\n",
      "0.8424166666666667\n",
      "0.8539166666666667\n",
      "0.8615\n",
      "0.8679166666666667\n",
      "0.87175\n",
      "0.8751666666666666\n",
      "0.8785833333333334\n",
      "0.8823333333333333\n",
      "0.88675\n",
      "0.8894166666666666\n",
      "0.89325\n",
      "0.8955833333333333\n",
      "0.8995\n",
      "0.9023333333333333\n",
      "0.906\n",
      "0.9080833333333334\n",
      "0.9105833333333333\n",
      "0.91375\n",
      "0.9159166666666667\n",
      "0.9169166666666667\n",
      "0.9191666666666667\n",
      "0.9208333333333333\n",
      "0.9231666666666667\n",
      "0.9248333333333333\n",
      "0.9259166666666667\n",
      "0.9274166666666667\n",
      "0.9284166666666667\n",
      "0.9305\n",
      "0.9315833333333333\n",
      "0.9339166666666666\n",
      "0.9345\n",
      "0.9364166666666667\n",
      "0.9365833333333333\n",
      "0.937\n",
      "0.9383333333333334\n",
      "0.9396666666666667\n",
      "0.9415\n",
      "0.9413333333333334\n",
      "0.9418333333333333\n",
      "0.9423333333333334\n",
      "0.9435833333333333\n",
      "0.9440833333333334\n",
      "0.94475\n",
      "0.9449166666666666\n",
      "0.9459166666666666\n",
      "0.946\n",
      "0.9465833333333333\n",
      "0.947\n",
      "0.9478333333333333\n",
      "0.9486666666666667\n",
      "0.94875\n",
      "0.94925\n",
      "0.95025\n",
      "0.9505\n",
      "0.9513333333333334\n",
      "0.9515833333333333\n",
      "0.952\n",
      "0.9529166666666666\n",
      "0.9529166666666666\n",
      "0.95425\n",
      "0.9546666666666667\n",
      "0.9545833333333333\n",
      "0.9555\n",
      "0.9555833333333333\n",
      "0.9556666666666667\n",
      "0.956\n",
      "0.9561666666666667\n",
      "0.9564166666666667\n",
      "0.9568333333333333\n",
      "0.9574166666666667\n",
      "0.9576666666666667\n",
      "0.9581666666666667\n",
      "0.9580833333333333\n",
      "0.9585\n",
      "0.95925\n",
      "0.9595\n",
      "0.9594166666666667\n",
      "0.9596666666666667\n",
      "0.9594166666666667\n",
      "0.9604166666666667\n",
      "0.9603333333333334\n",
      "0.9604166666666667\n",
      "0.96025\n",
      "0.9609166666666666\n",
      "0.9608333333333333\n",
      "0.9610833333333333\n",
      "0.96125\n",
      "0.9614166666666667\n",
      "0.9613333333333334\n",
      "0.9615\n",
      "0.9614166666666667\n",
      "0.96175\n",
      "0.9620833333333333\n",
      "0.9624166666666667\n",
      "0.9626666666666667\n",
      "0.9623333333333334\n",
      "0.96225\n",
      "0.9623333333333334\n",
      "0.9625833333333333\n",
      "0.9625\n",
      "0.9626666666666667\n",
      "0.9630833333333333\n",
      "0.9628333333333333\n",
      "0.9625833333333333\n",
      "0.9629166666666666\n",
      "0.963\n",
      "0.9635833333333333\n",
      "0.9635833333333333\n",
      "0.964\n",
      "0.9640833333333333\n",
      "0.9639166666666666\n",
      "0.9644166666666667\n",
      "0.9649166666666666\n",
      "0.9648333333333333\n",
      "0.9649166666666666\n",
      "0.9650833333333333\n",
      "0.9654166666666667\n",
      "0.9654166666666667\n",
      "0.9658333333333333\n",
      "0.9655833333333333\n",
      "0.9659166666666666\n",
      "0.9659166666666666\n",
      "0.9664166666666667\n",
      "0.9663333333333334\n",
      "0.9663333333333334\n",
      "0.9664166666666667\n",
      "0.9665\n",
      "0.9665833333333333\n",
      "0.9668333333333333\n",
      "0.9669166666666666\n",
      "0.967\n",
      "0.9668333333333333\n",
      "0.96625\n",
      "0.9665\n",
      "0.96725\n",
      "0.96725\n",
      "0.9675833333333334\n",
      "0.9674166666666667\n",
      "0.96775\n",
      "0.9679166666666666\n",
      "0.9678333333333333\n",
      "0.9681666666666666\n",
      "0.9681666666666666\n",
      "0.9685\n",
      "0.96825\n",
      "0.9684166666666667\n",
      "0.9683333333333334\n",
      "0.9685\n",
      "0.9684166666666667\n",
      "0.9685\n",
      "0.96825\n",
      "0.9689166666666666\n",
      "0.9686666666666667\n",
      "0.969\n",
      "0.9690833333333333\n",
      "0.9693333333333334\n",
      "0.9691666666666666\n",
      "0.9690833333333333\n",
      "0.9689166666666666\n",
      "0.9694166666666667\n",
      "0.96925\n",
      "0.9695\n",
      "0.9695833333333334\n",
      "0.9696666666666667\n",
      "0.9694166666666667\n",
      "0.9695833333333334\n",
      "0.9695\n",
      "0.9696666666666667\n",
      "0.96975\n",
      "0.9699166666666666\n",
      "0.9699166666666666\n",
      "0.9695833333333334\n",
      "0.9698333333333333\n",
      "0.9700833333333333\n",
      "0.9700833333333333\n",
      "0.9701666666666666\n",
      "0.9698333333333333\n",
      "0.97\n",
      "0.9701666666666666\n",
      "0.9700833333333333\n",
      "0.9700833333333333\n",
      "0.9701666666666666\n",
      "0.9701666666666666\n",
      "0.97\n",
      "0.96975\n",
      "0.9701666666666666\n",
      "0.97025\n",
      "0.9700833333333333\n",
      "0.9701666666666666\n",
      "0.9699166666666666\n",
      "0.97025\n",
      "0.97025\n",
      "0.9701666666666666\n",
      "0.9705\n",
      "0.97025\n",
      "0.9701666666666666\n",
      "0.9705833333333334\n",
      "0.9705\n",
      "Accuracy: 0.9705\n"
     ]
    }
   ],
   "source": [
    "gbm, valid_accuracies =train_lgbm_with_custom_loss(X_train, X_val, y_train, y_val)\n",
    "y_pred = gbm.predict(X_val)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_val, y_pred.argmax(-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"sup_multi_valid_accuracies.npy\", valid_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
