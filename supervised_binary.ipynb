{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 50\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "BAG_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = load_mnist_pca_train_test_val(\n",
    "    n_components=N_COMPONENTS, test_size=TEST_SIZE, val_size=VAL_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = rewrite_label_with_binary_setting(X_train, y_train)\n",
    "X_val, y_val = rewrite_label_with_binary_setting(X_val, y_val)\n",
    "X_test, y_test = rewrite_label_with_binary_setting(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_with_custom_loss(X_train, X_valid, y_train, y_valid):\n",
    "\n",
    "    \"\"\"Train LightGBM with custom loss function.\"\"\"\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, free_raw_data=False)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"verbose\": -1,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"num_boost_round\": 200,\n",
    "    }\n",
    "    valid_accuracies = []\n",
    "\n",
    "    def record_accuracies(p: lgb.Booster, train_data: lgb.Dataset, valid_data: lgb.Dataset):\n",
    "        valid_pred = (p.predict(valid_data.data) > 0.5).astype(int)\n",
    "        valid_acc = accuracy_score(valid_data.label, valid_pred)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        print(valid_acc)\n",
    "    \n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lambda p: record_accuracies(p.model, train_data, valid_data)]\n",
    "    )\n",
    "    return gbm, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryoma.kobayashi/gits/techblog_git/wsl_w_lgbm/.venv/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8533333333333334\n",
      "0.86025\n",
      "0.8633333333333333\n",
      "0.8683333333333333\n",
      "0.87575\n",
      "0.8825833333333334\n",
      "0.8883333333333333\n",
      "0.8975833333333333\n",
      "0.8990833333333333\n",
      "0.9051666666666667\n",
      "0.9071666666666667\n",
      "0.9095833333333333\n",
      "0.9141666666666667\n",
      "0.9173333333333333\n",
      "0.9173333333333333\n",
      "0.9191666666666667\n",
      "0.92125\n",
      "0.92325\n",
      "0.92625\n",
      "0.92725\n",
      "0.9275\n",
      "0.9280833333333334\n",
      "0.93\n",
      "0.93175\n",
      "0.9326666666666666\n",
      "0.9339166666666666\n",
      "0.93425\n",
      "0.9350833333333334\n",
      "0.9364166666666667\n",
      "0.9370833333333334\n",
      "0.9381666666666667\n",
      "0.9398333333333333\n",
      "0.9396666666666667\n",
      "0.9414166666666667\n",
      "0.9421666666666667\n",
      "0.9426666666666667\n",
      "0.9441666666666667\n",
      "0.9440833333333334\n",
      "0.94525\n",
      "0.9456666666666667\n",
      "0.94625\n",
      "0.9463333333333334\n",
      "0.9469166666666666\n",
      "0.9471666666666667\n",
      "0.948\n",
      "0.9485833333333333\n",
      "0.94975\n",
      "0.95\n",
      "0.9500833333333333\n",
      "0.9505\n",
      "0.95125\n",
      "0.95025\n",
      "0.951\n",
      "0.9524166666666667\n",
      "0.9531666666666667\n",
      "0.9536666666666667\n",
      "0.9538333333333333\n",
      "0.9544166666666667\n",
      "0.9549166666666666\n",
      "0.9554166666666667\n",
      "0.9554166666666667\n",
      "0.9558333333333333\n",
      "0.9561666666666667\n",
      "0.9568333333333333\n",
      "0.9570833333333333\n",
      "0.95725\n",
      "0.9568333333333333\n",
      "0.957\n",
      "0.9580833333333333\n",
      "0.9591666666666666\n",
      "0.9594166666666667\n",
      "0.95925\n",
      "0.9593333333333334\n",
      "0.9599166666666666\n",
      "0.9605\n",
      "0.9606666666666667\n",
      "0.9608333333333333\n",
      "0.9613333333333334\n",
      "0.9613333333333334\n",
      "0.96175\n",
      "0.9613333333333334\n",
      "0.9616666666666667\n",
      "0.96125\n",
      "0.96175\n",
      "0.9619166666666666\n",
      "0.9618333333333333\n",
      "0.9624166666666667\n",
      "0.9626666666666667\n",
      "0.9629166666666666\n",
      "0.9629166666666666\n",
      "0.9635\n",
      "0.9635\n",
      "0.9634166666666667\n",
      "0.9636666666666667\n",
      "0.9638333333333333\n",
      "0.9634166666666667\n",
      "0.9635\n",
      "0.9639166666666666\n",
      "0.9640833333333333\n",
      "0.96425\n",
      "0.9641666666666666\n",
      "0.9645\n",
      "0.9648333333333333\n",
      "0.9650833333333333\n",
      "0.9654166666666667\n",
      "0.9654166666666667\n",
      "0.9653333333333334\n",
      "0.9654166666666667\n",
      "0.9656666666666667\n",
      "0.9663333333333334\n",
      "0.9664166666666667\n",
      "0.96625\n",
      "0.9665\n",
      "0.9664166666666667\n",
      "0.9661666666666666\n",
      "0.9664166666666667\n",
      "0.9666666666666667\n",
      "0.9671666666666666\n",
      "0.967\n",
      "0.967\n",
      "0.9675\n",
      "0.96775\n",
      "0.968\n",
      "0.96775\n",
      "0.968\n",
      "0.968\n",
      "0.96825\n",
      "0.9680833333333333\n",
      "0.96825\n",
      "0.9681666666666666\n",
      "0.9684166666666667\n",
      "0.9686666666666667\n",
      "0.9686666666666667\n",
      "0.9688333333333333\n",
      "0.9686666666666667\n",
      "0.9695\n",
      "0.9695833333333334\n",
      "0.9695\n",
      "0.9691666666666666\n",
      "0.9694166666666667\n",
      "0.9693333333333334\n",
      "0.9698333333333333\n",
      "0.9701666666666666\n",
      "0.9700833333333333\n",
      "0.9698333333333333\n",
      "0.9700833333333333\n",
      "0.97\n",
      "0.9700833333333333\n",
      "0.9704166666666667\n",
      "0.9701666666666666\n",
      "0.97025\n",
      "0.9700833333333333\n",
      "0.9700833333333333\n",
      "0.97\n",
      "0.9703333333333334\n",
      "0.97025\n",
      "0.9705\n",
      "0.9705833333333334\n",
      "0.97075\n",
      "0.9708333333333333\n",
      "0.9708333333333333\n",
      "0.971\n",
      "0.9710833333333333\n",
      "0.9715\n",
      "0.9715\n",
      "0.9713333333333334\n",
      "0.9715\n",
      "0.9716666666666667\n",
      "0.9716666666666667\n",
      "0.9716666666666667\n",
      "0.9719166666666667\n",
      "0.9719166666666667\n",
      "0.97175\n",
      "0.9716666666666667\n",
      "0.97175\n",
      "0.9716666666666667\n",
      "0.9718333333333333\n",
      "0.9718333333333333\n",
      "0.972\n",
      "0.9721666666666666\n",
      "0.9723333333333334\n",
      "0.9725\n",
      "0.9723333333333334\n",
      "0.9725833333333334\n",
      "0.9725\n",
      "0.9723333333333334\n",
      "0.97275\n",
      "0.973\n",
      "0.9731666666666666\n",
      "0.973\n",
      "0.973\n",
      "0.9733333333333334\n",
      "0.9733333333333334\n",
      "0.9735\n",
      "0.9733333333333334\n",
      "0.9734166666666667\n",
      "0.9735833333333334\n",
      "0.9735833333333334\n",
      "0.9735833333333334\n",
      "0.9733333333333334\n",
      "Accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "gbm, valid_accuracies =train_lgbm_with_custom_loss(X_train, X_val, y_train, y_val)\n",
    "y_pred = gbm.predict(X_val)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_val, (y_pred > 0.5).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"sup_bin_valid_accuracies.npy\", valid_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
